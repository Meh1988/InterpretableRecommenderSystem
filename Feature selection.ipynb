{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "from collections import defaultdict\n",
    "import re \n",
    "from bs4 import BeautifulSoup \n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from keras.callbacks import ModelCheckpoint    \n",
    "from keras.layers import Dense, Input, Flatten, Add, Multiply, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer \n",
    "from make_data import generate_data\n",
    "import json\n",
    "import random\n",
    "from keras import optimizers\n",
    "\n",
    "BATCH_SIZE = 1000\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "random.seed(0)\n",
    "# The number of key features for each data set.\n",
    "ks = {'orange_skin': 4, 'XOR': 2, 'nonlinear_additive': 4, 'switch': 5}\n",
    "\n",
    "def create_data(datatype, n = 1000): \n",
    "\t\"\"\"\n",
    "\tCreate train and validation datasets.\n",
    "\n",
    "\t\"\"\"\n",
    "\tx_train, y_train, _ = generate_data(n = n, \n",
    "\t\tdatatype = datatype, seed = 0)  \n",
    "\tx_val, y_val, datatypes_val = generate_data(n = 10 ** 5, \n",
    "\t\tdatatype = datatype, seed = 1)  \n",
    "\n",
    "\tinput_shape = x_train.shape[1] \n",
    "\n",
    "\treturn x_train,y_train,x_val,y_val,datatypes_val, input_shape\n",
    "\n",
    "def create_rank(scores, k): \n",
    "\t\"\"\"\n",
    "\tCompute rank of each feature based on weight.\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tscores = abs(scores)\n",
    "\tn, d = scores.shape\n",
    "\tranks = []\n",
    "\tfor i, score in enumerate(scores):\n",
    "\t\t# Random permutation to avoid bias due to equal weights.\n",
    "\t\tidx = np.random.permutation(d) \n",
    "\t\tpermutated_weights = score[idx]  \n",
    "\t\tpermutated_rank=(-permutated_weights).argsort().argsort()+1\n",
    "\t\trank = permutated_rank[np.argsort(idx)]\n",
    "\n",
    "\t\tranks.append(rank)\n",
    "\n",
    "\treturn np.array(ranks)\n",
    "\n",
    "def compute_median_rank(scores, k, datatype_val = None):\n",
    "\tranks = create_rank(scores, k)\n",
    "\tif datatype_val is None: \n",
    "\t\tmedian_ranks = np.median(ranks[:,:k], axis = 1)\n",
    "\telse:\n",
    "\t\tdatatype_val = datatype_val[:len(scores)]\n",
    "\t\tmedian_ranks1 = np.median(ranks[datatype_val == 'orange_skin',:][:,np.array([0,1,2,3,9])], \n",
    "\t\t\taxis = 1)\n",
    "\t\tmedian_ranks2 = np.median(ranks[datatype_val == 'nonlinear_additive',:][:,np.array([4,5,6,7,9])], \n",
    "\t\t\taxis = 1)\n",
    "\t\tmedian_ranks = np.concatenate((median_ranks1,median_ranks2), 0)\n",
    "\treturn median_ranks \n",
    "\n",
    "class Sample_Concrete(Layer):\n",
    "\t\"\"\"\n",
    "\tLayer for sample Concrete / Gumbel-Softmax variables. \n",
    "\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, tau0, k, **kwargs): \n",
    "\t\tself.tau0 = tau0\n",
    "\t\tself.k = k\n",
    "\t\tsuper(Sample_Concrete, self).__init__(**kwargs)\n",
    "\n",
    "\tdef call(self, logits):   \n",
    "\t\t# logits: [BATCH_SIZE, d]\n",
    "\t\tlogits_ = K.expand_dims(logits, -2)# [BATCH_SIZE, 1, d]\n",
    "\n",
    "\t\tbatch_size = tf.shape(logits_)[0]\n",
    "\t\td = tf.shape(logits_)[2]\n",
    "\t\tuniform = tf.random_uniform(shape =(batch_size, self.k, d), \n",
    "\t\t\tminval = np.finfo(tf.float32.as_numpy_dtype).tiny,\n",
    "\t\t\tmaxval = 1.0)\n",
    "\n",
    "\t\tgumbel = - K.log(-K.log(uniform))\n",
    "\t\tnoisy_logits = (gumbel + logits_)/self.tau0\n",
    "\t\tsamples = K.softmax(noisy_logits)\n",
    "\t\tsamples = K.max(samples, axis = 1) \n",
    "\n",
    "\t\t# Explanation Stage output.\n",
    "\t\tthreshold = tf.expand_dims(tf.nn.top_k(logits, self.k, sorted = True)[0][:,-1], -1)\n",
    "\t\tdiscrete_logits = tf.cast(tf.greater_equal(logits,threshold),tf.float32)\n",
    "\t\t\n",
    "\t\treturn K.in_train_phase(samples, discrete_logits)\n",
    "\n",
    "\tdef compute_output_shape(self, input_shape):\n",
    "\t\treturn input_shape \n",
    "\n",
    "\n",
    "\n",
    "def L2X(datatype, train = True): \n",
    "\tx_train,y_train,x_val,y_val,datatype_val, input_shape = create_data(datatype, \n",
    "\t\tn = int(1e6))\n",
    "\t \n",
    "\tst1 = time.time()\n",
    "\tst2 = st1\n",
    "\n",
    "\tactivation = 'relu' if datatype in ['orange_skin','XOR'] else 'selu'\n",
    "\t# P(S|X)\n",
    "\tmodel_input = Input(shape=(input_shape,), dtype='float32') \n",
    "\n",
    "\tnet = Dense(100, activation=activation, name = 's/dense1',\n",
    "\t\tkernel_regularizer=regularizers.l2(1e-3))(model_input)\n",
    "\tnet = Dense(100, activation=activation, name = 's/dense2',\n",
    "\t\tkernel_regularizer=regularizers.l2(1e-3))(net) \n",
    "\n",
    "\t# A tensor of shape, [batch_size, max_sents, 100]\n",
    "\tlogits = Dense(input_shape)(net) \n",
    "\t# [BATCH_SIZE, max_sents, 1]  \n",
    "\tk = ks[datatype]; tau = 0.1\n",
    "\tsamples = Sample_Concrete(tau, k, name = 'sample')(logits)\n",
    "\n",
    "\t# q(X_S)\n",
    "\tnew_model_input = Multiply()([model_input, samples]) \n",
    "\tnet = Dense(200, activation=activation, name = 'dense1',\n",
    "\t\tkernel_regularizer=regularizers.l2(1e-3))(new_model_input) \n",
    "\tnet = BatchNormalization()(net) # Add batchnorm for stability.\n",
    "\tnet = Dense(200, activation=activation, name = 'dense2',\n",
    "\t\tkernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "\tnet = BatchNormalization()(net)\n",
    "\n",
    "\tpreds = Dense(2, activation='softmax', name = 'dense4',\n",
    "\t\tkernel_regularizer=regularizers.l2(1e-3))(net) \n",
    "\tmodel = Model(model_input, preds)\n",
    "\n",
    "\tif train: \n",
    "\t\tadam = optimizers.Adam(lr = 1e-3)\n",
    "\t\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\t\t  optimizer=adam,\n",
    "\t\t\t\t\t  metrics=['acc']) \n",
    "\t\tfilepath=\"models/{}/L2X.hdf5\".format(datatype)\n",
    "\t\tcheckpoint = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "\t\t\tverbose=1, save_best_only=True, mode='max')\n",
    "\t\tcallbacks_list = [checkpoint]\n",
    "\t\tmodel.fit(x_train, y_train, validation_data=(x_val, y_val),callbacks = callbacks_list, epochs=1, batch_size=BATCH_SIZE)\n",
    "\t\tst2 = time.time() \n",
    "\telse:\n",
    "\t\tmodel.load_weights('models/{}/L2X.hdf5'.format(datatype), \n",
    "\t\t\tby_name=True) \n",
    "\n",
    "\n",
    "\tpred_model = Model(model_input, samples)\n",
    "\tpred_model.compile(loss=None,\n",
    "\t\t\t\t  optimizer='rmsprop',\n",
    "\t\t\t\t  metrics=[None]) \n",
    "\n",
    "\tscores = pred_model.predict(x_val, verbose = 1, batch_size = BATCH_SIZE) \n",
    "\n",
    "\tmedian_ranks = compute_median_rank(scores, k = ks[datatype],\n",
    "\t\tdatatype_val=datatype_val)\n",
    "\n",
    "\treturn median_ranks, time.time() - st2, st2 - st1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\timport argparse\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\n",
    "\tparser.add_argument('--datatype', type = str, \n",
    "\t\tchoices = ['orange_skin','XOR','nonlinear_additive','switch'], default = 'orange_skin')\n",
    "\tparser.add_argument('--train', action='store_true')\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\n",
    "\tmedian_ranks, exp_time, train_time = L2X(datatype = args.datatype, \n",
    "\t\ttrain = args.train)\n",
    "\toutput = 'datatype:{}, mean:{}, sd:{}, train time:{}s, explain time:{}s \\n'.format( \n",
    "\t\targs.datatype, \n",
    "\t\tnp.mean(median_ranks), \n",
    "\t\tnp.std(median_ranks),\n",
    "\t\ttrain_time, exp_time)\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
